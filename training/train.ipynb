{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell4/miniconda3/envs/gnn_train/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch_scatter import scatter_mean\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import normalized_cut, to_dense_batch, from_networkx\n",
    "from torch_geometric.nn import MetaLayer, SplineConv, max_pool, GlobalAttention\n",
    "from torch_geometric.transforms import FaceToEdge, Cartesian\n",
    "from torch_geometric.data import Batch, Data, Dataset\n",
    "from utils.distributions import *\n",
    "\n",
    "from utils import mol2graph\n",
    "from utils.data import read_ply\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "import py3Dmol\n",
    "#import pymesh\n",
    "from plyfile import PlyData\n",
    "\n",
    "DATA_PATH = '/home/dell4/king/202112_graphDrug/data_v2/PDBbind_v2020_other_PL/v2020-other-PL_minimized_copy/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# ID = '1a42'\n",
    "\n",
    "# # GET PROTEIN MESH\n",
    "# target_ply = DATA_PATH+'%s/%s_protein.ply'%(ID, ID)\n",
    "# target_mesh = Cartesian()(FaceToEdge()(read_ply(target_ply)))\n",
    "# # GET MOLECULE NETWORK\n",
    "# real_mol = Chem.MolFromMol2File(DATA_PATH+'%s/%s_ligand.mol2'%(ID, ID),sanitize=False, cleanupSubstructures=False)\n",
    "# mol_ntwk = from_networkx(mol2graph.mol_to_nx(real_mol))\n",
    "\n",
    "# mol_ntwk, target_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved data file. loading...\n",
      "Found 13785 complexes\n"
     ]
    }
   ],
   "source": [
    "# Prepare data files for training\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "\n",
    "def load_data(f_path):\n",
    "    with open(f_path, 'rb') as f:\n",
    "        mynewlist = pickle.load(f)\n",
    "        return mynewlist\n",
    "\n",
    "if os.path.exists('/home/dell4/king/202112_graphDrug/data_v2/v2020-other-PL_minimized.pkl'):\n",
    "    print('Found saved data file. loading...')\n",
    "    processed_data = load_data('/home/dell4/king/202112_graphDrug/data_v2/v2020-other-PL_minimized.pkl')\n",
    "    print('Found %s complexes'%(len(processed_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexes in training set: 11028\n",
      "Complexes in test set: 2757\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from model_v3 import LigandNet, TargetNet, AlphaDock, mdn_loss_fn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "# Split data and generate loaders\n",
    "from torch_geometric.loader import DataLoader\n",
    "split = int(len(processed_data)*0.8)\n",
    "train_data = processed_data[:split]\n",
    "test_data = processed_data[split:]\n",
    "print('Complexes in training set:', len(train_data))\n",
    "print('Complexes in test set:', len(test_data))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "ligand_model = LigandNet(28, residual_layers=10, dropout_rate=0.10)\n",
    "target_model = TargetNet(3, residual_layers=10, dropout_rate=0.10)\n",
    "model_1 = AlphaDock(ligand_model, target_model, hidden_dim=64, n_gaussians=10, dropout_rate=0.10, dist_threshold=7.).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.0001,\n",
    "                              betas=(0.9, 0.999), \n",
    "                              eps=1e-06, weight_decay=0.01)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "save_each=50\n",
    "aux_weight = 0.001\n",
    "losses = []\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1778"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(loader, model):\n",
    "    total_loss, mdn_loss, atom_loss, bond_loss, count = 0, 0, 0, 0, 0\n",
    "    for data in loader:  \n",
    "        count+=1\n",
    "        model.train()\n",
    "        target, ligand = data\n",
    "        ligand, target = ligand.to(device), target.to(device)\n",
    "\n",
    "        if torch.isnan(target.x).any() or torch.isnan(target.edge_attr).any() or torch.isnan(target.pos).any():\n",
    "            print('nan check failed for', count, '. Skipping step.')\n",
    "        elif torch.isnan(ligand.x).any() or torch.isnan(ligand.edge_attr).any() or torch.isnan(ligand.pos).any():\n",
    "            print('nan check failed for', count, '. Skipping step.')\n",
    "        else:            \n",
    "            atom_labels = torch.argmax(ligand.x, dim=1, keepdim=False)\n",
    "            bond_labels = torch.argmax(ligand.edge_attr, dim=1, keepdim=False)\n",
    "\n",
    "            pi, sigma, mu, dist, atom_types, bond_types, batch = model(ligand, target)\n",
    "            mdn = mdn_loss_fn(pi, sigma, mu, dist)\n",
    "            mdn = mdn[torch.where(dist <= model.dist_threhold)[0]]\n",
    "            mdn = mdn.mean()\n",
    "            atom = F.cross_entropy(atom_types, atom_labels)\n",
    "            bond = F.cross_entropy(bond_types, bond_labels)\n",
    "            loss = mdn + (atom * aux_weight) + (bond * aux_weight)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item() * (ligand.batch.max().item() + 1)\n",
    "            mdn_loss += mdn.item() * (ligand.batch.max().item() + 1)\n",
    "            atom_loss += atom.item() * (ligand.batch.max().item() + 1)\n",
    "            bond_loss += bond.item() * (ligand.batch.max().item() + 1)\n",
    "        # except:\n",
    "        #     print('ERROR at', count)\n",
    "        #     target, ligand = data\n",
    "        #     print('NAN CHECK', torch.isnan(target.x).any(), torch.isnan(target.edge_attr).any(), torch.isnan(target.pos).any())\n",
    "        #     #print(target.x, target.edge_attr, target.pos)\n",
    "        #     #print(ligand.x, ligand.edge_attr, ligand.pos)\n",
    "        #     break\n",
    "        \n",
    "    return total_loss / len(loader.dataset), mdn_loss / len(loader.dataset), atom_loss / len(loader.dataset), bond_loss / len(loader.dataset)\n",
    "\n",
    "def test(loader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss, mdn_loss, atom_loss, bond_loss, count = 0, 0, 0, 0, 0\n",
    "        for data in loader:\n",
    "            count+=1\n",
    "            target ,ligand = data\n",
    "            ligand, target = ligand.to(device), target.to(device)\n",
    "\n",
    "            if torch.isnan(target.x).any() or torch.isnan(target.edge_attr).any() or torch.isnan(target.pos).any():\n",
    "                print('nan check failed for', count, '. Skipping step.')\n",
    "            elif torch.isnan(ligand.x).any() or torch.isnan(ligand.edge_attr).any() or torch.isnan(ligand.pos).any():\n",
    "                print('nan check failed for', count, '. Skipping step.')\n",
    "            else:    \n",
    "                atom_labels = torch.argmax(ligand.x, dim=1, keepdim=False)\n",
    "                bond_labels = torch.argmax(ligand.edge_attr, dim=1, keepdim=False)\n",
    "                \n",
    "                pi, sigma, mu, dist, atom_types, bond_types, batch = model(ligand, target)\n",
    "                    \n",
    "                mdn = mdn_loss_fn(pi, sigma, mu, dist)\n",
    "                mdn = mdn[torch.where(dist <= model.dist_threhold)[0]]\n",
    "                mdn = mdn.mean()\n",
    "                atom = F.cross_entropy(atom_types, atom_labels)\n",
    "                bond = F.cross_entropy(bond_types, bond_labels)\n",
    "                loss = mdn + (atom * aux_weight) + (bond * aux_weight)\n",
    "                \n",
    "                total_loss += loss.item() * (ligand.batch.max().item() + 1)\n",
    "                mdn_loss += mdn.item() * (ligand.batch.max().item() + 1)\n",
    "                atom_loss += atom.item() * (ligand.batch.max().item() + 1)\n",
    "                bond_loss += bond.item() * (ligand.batch.max().item() + 1)\n",
    "\n",
    "        test_total_loss = total_loss / len(loader.dataset)                                                        \n",
    "        test_mdn_loss = mdn_loss / len(loader.dataset)\n",
    "        test_atom_loss = atom_loss / len(loader.dataset)\n",
    "        test_bond_loss = bond_loss / len(loader.dataset)\n",
    "    return test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss\n",
    "\n",
    "prev_test_total_loss = 1000\n",
    "import pandas as pd\n",
    "for epoch in range(1, epochs+1):\n",
    "    print('[EPOCH # {}/{}]'.format(epoch, epochs))\n",
    "    total_loss, mdn_loss, atom_loss, bond_loss = train(loader_train, model_1)\n",
    "    test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss = test(loader_test, model_1)\n",
    "    print('Epoch train: {:03d}, Total Loss: {:.3f}, MDN: {:.3f}, Atom: {:.3f}, Bond: {:.3f}'.format(epoch, total_loss, mdn_loss, atom_loss, bond_loss))\n",
    "    print('Epoch test: {:03d}, Total Loss: {:.3f}, MDN: {:.3f}, Atom: {:.3f}, Bond: {:.3f}'.format(epoch, test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss))\n",
    "    \n",
    "    losses.append([total_loss, mdn_loss, atom_loss, bond_loss, test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss])\n",
    "    if test_total_loss<=prev_test_total_loss:\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': model_1.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'rng_state': torch.get_rng_state(), 'total_loss': total_loss,  \n",
    "                    'mdn_loss': mdn_loss, 'atom_loss': atom_loss, 'bond_loss': bond_loss}, 'checkpoints/model_alphadock_minloss.chk')\n",
    "\n",
    "l = pd.DataFrame(losses, columns= ['total_loss', 'mdn_loss', 'atom_loss', 'bond_loss', 'test_total_loss', 'test_mdn_loss', 'test_atom_loss', 'test_bond_loss'])\n",
    "l.to_csv('checkpoints/AlphaDock_pdbbindv2019_13K_loss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model image\n",
    "# from torchviz import make_dot\n",
    "# y = model(loader_train.dataset[1][1].to(device), loader_train.dataset[1][0].to(device))\n",
    "# make_dot(y, params=dict(model.named_parameters())).render(\"attached\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at 1 911\n",
      "Error at 1 968\n",
      "Error at 1 1014\n",
      "Error at 1 1156\n",
      "Epoch: 001, Total Loss: 1.953, MDN: 1.949, Atom: 2.593, Bond: 1.288\n",
      "Error at 2 20\n",
      "Error at 2 25\n",
      "Error at 2 640\n",
      "Error at 2 897\n",
      "Epoch: 002, Total Loss: 1.654, MDN: 1.650, Atom: 2.166, Bond: 1.230\n",
      "Error at 3 570\n",
      "Error at 3 747\n",
      "Error at 3 1023\n",
      "Error at 3 1253\n",
      "Epoch: 003, Total Loss: 1.633, MDN: 1.629, Atom: 2.381, Bond: 1.337\n",
      "Error at 4 67\n",
      "Error at 4 121\n",
      "Error at 4 681\n",
      "Error at 4 1004\n",
      "Epoch: 004, Total Loss: 1.622, MDN: 1.618, Atom: 2.613, Bond: 1.439\n",
      "Error at 5 139\n",
      "Error at 5 438\n",
      "Error at 5 870\n",
      "Error at 5 1300\n",
      "Epoch: 005, Total Loss: 1.614, MDN: 1.610, Atom: 2.840, Bond: 1.543\n",
      "Error at 6 402\n",
      "Error at 6 639\n",
      "Error at 6 745\n",
      "Error at 6 759\n",
      "Epoch: 006, Total Loss: 1.596, MDN: 1.591, Atom: 2.995, Bond: 1.626\n",
      "Error at 7 104\n",
      "Error at 7 640\n",
      "Error at 7 1077\n",
      "Error at 7 1130\n",
      "Epoch: 007, Total Loss: 1.589, MDN: 1.584, Atom: 3.083, Bond: 1.673\n",
      "Error at 8 222\n",
      "Error at 8 236\n",
      "Error at 8 823\n",
      "Error at 8 1225\n",
      "Epoch: 008, Total Loss: 1.584, MDN: 1.579, Atom: 3.137, Bond: 1.699\n",
      "Error at 9 350\n",
      "Error at 9 823\n",
      "Error at 9 849\n",
      "Error at 9 1235\n",
      "Epoch: 009, Total Loss: 1.591, MDN: 1.586, Atom: 3.173, Bond: 1.713\n",
      "Error at 10 229\n",
      "Error at 10 418\n",
      "Error at 10 660\n",
      "Error at 10 1004\n",
      "Epoch: 010, Total Loss: 1.581, MDN: 1.576, Atom: 3.197, Bond: 1.719\n",
      "Error at 11 345\n",
      "Error at 11 654\n",
      "Error at 11 754\n",
      "Error at 11 1173\n",
      "Epoch: 011, Total Loss: 1.574, MDN: 1.569, Atom: 3.214, Bond: 1.729\n",
      "Error at 12 75\n",
      "Error at 12 106\n",
      "Error at 12 1236\n",
      "Error at 12 1292\n",
      "Epoch: 012, Total Loss: 1.573, MDN: 1.568, Atom: 3.224, Bond: 1.734\n",
      "Error at 13 5\n",
      "Error at 13 375\n",
      "Error at 13 1206\n",
      "Error at 13 1339\n",
      "Epoch: 013, Total Loss: 1.570, MDN: 1.565, Atom: 3.228, Bond: 1.733\n",
      "Error at 14 810\n",
      "Error at 14 899\n",
      "Error at 14 1034\n",
      "Error at 14 1206\n",
      "Epoch: 014, Total Loss: 1.568, MDN: 1.563, Atom: 3.233, Bond: 1.735\n",
      "Error at 15 11\n",
      "Error at 15 1152\n",
      "Error at 15 1318\n",
      "Error at 15 1335\n",
      "Epoch: 015, Total Loss: 1.567, MDN: 1.562, Atom: 3.238, Bond: 1.737\n",
      "Error at 16 171\n",
      "Error at 16 299\n",
      "Error at 16 500\n",
      "Error at 16 1057\n",
      "Epoch: 016, Total Loss: 1.566, MDN: 1.561, Atom: 3.238, Bond: 1.734\n",
      "Error at 17 384\n",
      "Error at 17 669\n",
      "Error at 17 1200\n",
      "Error at 17 1246\n",
      "Epoch: 017, Total Loss: 1.565, MDN: 1.560, Atom: 3.245, Bond: 1.740\n",
      "Error at 18 223\n",
      "Error at 18 564\n",
      "Error at 18 1112\n",
      "Error at 18 1152\n",
      "Epoch: 018, Total Loss: 1.565, MDN: 1.560, Atom: 3.243, Bond: 1.736\n",
      "Error at 19 235\n",
      "Error at 19 426\n",
      "Error at 19 519\n",
      "Error at 19 754\n",
      "Epoch: 019, Total Loss: 1.564, MDN: 1.559, Atom: 3.248, Bond: 1.740\n",
      "Error at 20 41\n",
      "Error at 20 253\n",
      "Error at 20 262\n",
      "Error at 20 539\n",
      "Epoch: 020, Total Loss: 1.564, MDN: 1.559, Atom: 3.246, Bond: 1.736\n",
      "Error at 21 287\n",
      "Error at 21 456\n",
      "Error at 21 620\n",
      "Error at 21 676\n",
      "Epoch: 021, Total Loss: 1.563, MDN: 1.558, Atom: 3.246, Bond: 1.734\n",
      "Error at 22 109\n",
      "Error at 22 274\n",
      "Error at 22 481\n",
      "Error at 22 940\n",
      "Epoch: 022, Total Loss: 1.562, MDN: 1.557, Atom: 3.251, Bond: 1.740\n",
      "Error at 23 150\n",
      "Error at 23 159\n",
      "Error at 23 402\n",
      "Error at 23 1146\n",
      "Epoch: 023, Total Loss: 1.563, MDN: 1.558, Atom: 3.252, Bond: 1.740\n",
      "Error at 24 232\n",
      "Error at 24 269\n",
      "Error at 24 428\n",
      "Error at 24 631\n",
      "Epoch: 024, Total Loss: 1.561, MDN: 1.556, Atom: 3.250, Bond: 1.737\n",
      "Error at 25 149\n",
      "Error at 25 765\n",
      "Error at 25 1109\n",
      "Error at 25 1216\n",
      "Epoch: 025, Total Loss: 1.561, MDN: 1.556, Atom: 3.252, Bond: 1.738\n",
      "Error at 26 447\n",
      "Error at 26 501\n",
      "Error at 26 1077\n",
      "Error at 26 1109\n",
      "Epoch: 026, Total Loss: 1.560, MDN: 1.555, Atom: 3.253, Bond: 1.739\n",
      "Error at 27 41\n",
      "Error at 27 573\n",
      "Error at 27 709\n",
      "Error at 27 1228\n",
      "Epoch: 027, Total Loss: 1.569, MDN: 1.564, Atom: 3.254, Bond: 1.738\n",
      "Error at 28 221\n",
      "Error at 28 883\n",
      "Error at 28 1052\n",
      "Error at 28 1329\n",
      "Epoch: 028, Total Loss: 1.563, MDN: 1.558, Atom: 3.252, Bond: 1.736\n",
      "Error at 29 516\n",
      "Error at 29 844\n",
      "Error at 29 884\n",
      "Error at 29 1250\n",
      "Epoch: 029, Total Loss: 1.561, MDN: 1.556, Atom: 3.251, Bond: 1.733\n",
      "Error at 30 357\n",
      "Error at 30 816\n",
      "Error at 30 1063\n",
      "Error at 30 1276\n",
      "Epoch: 030, Total Loss: 1.560, MDN: 1.555, Atom: 3.252, Bond: 1.734\n",
      "Error at 31 283\n",
      "Error at 31 294\n",
      "Error at 31 376\n",
      "Error at 31 655\n",
      "Epoch: 031, Total Loss: 1.559, MDN: 1.554, Atom: 3.256, Bond: 1.738\n",
      "Error at 32 205\n",
      "Error at 32 729\n",
      "Error at 32 770\n",
      "Error at 32 1260\n",
      "Epoch: 032, Total Loss: 1.558, MDN: 1.553, Atom: 3.255, Bond: 1.737\n",
      "Error at 33 239\n",
      "Error at 33 359\n",
      "Error at 33 808\n",
      "Error at 33 1162\n",
      "Epoch: 033, Total Loss: 1.557, MDN: 1.552, Atom: 3.256, Bond: 1.737\n",
      "Error at 34 318\n",
      "Error at 34 1202\n",
      "Error at 34 1337\n",
      "Error at 34 1362\n",
      "Epoch: 034, Total Loss: 1.556, MDN: 1.551, Atom: 3.255, Bond: 1.736\n",
      "Error at 35 388\n",
      "Error at 35 398\n",
      "Error at 35 400\n",
      "Error at 35 588\n",
      "Epoch: 035, Total Loss: 1.555, MDN: 1.550, Atom: 3.257, Bond: 1.737\n",
      "Error at 36 516\n",
      "Error at 36 699\n",
      "Error at 36 727\n",
      "Error at 36 885\n",
      "Epoch: 036, Total Loss: 1.554, MDN: 1.549, Atom: 3.255, Bond: 1.734\n",
      "Error at 37 456\n",
      "Error at 37 497\n",
      "Error at 37 646\n",
      "Error at 37 687\n",
      "Epoch: 037, Total Loss: 1.552, MDN: 1.547, Atom: 3.251, Bond: 1.730\n",
      "Error at 38 179\n",
      "Error at 38 632\n",
      "Error at 38 925\n",
      "Error at 38 990\n",
      "Epoch: 038, Total Loss: 1.551, MDN: 1.546, Atom: 3.251, Bond: 1.729\n",
      "Error at 39 198\n",
      "Error at 39 577\n",
      "Error at 39 639\n",
      "Error at 39 1231\n",
      "Epoch: 039, Total Loss: 1.550, MDN: 1.545, Atom: 3.254, Bond: 1.732\n",
      "Error at 40 522\n",
      "Error at 40 645\n",
      "Error at 40 728\n",
      "Epoch: 040, Total Loss: 1.551, MDN: 1.546, Atom: 3.253, Bond: 1.729\n",
      "Error at 41 492\n",
      "Error at 41 850\n",
      "Error at 41 1283\n",
      "Error at 41 1330\n",
      "Epoch: 041, Total Loss: 1.548, MDN: 1.543, Atom: 3.249, Bond: 1.725\n",
      "Error at 42 59\n",
      "Error at 42 245\n",
      "Error at 42 289\n",
      "Error at 42 494\n",
      "Epoch: 042, Total Loss: 1.548, MDN: 1.543, Atom: 3.249, Bond: 1.725\n",
      "Error at 43 122\n",
      "Error at 43 570\n",
      "Error at 43 918\n",
      "Error at 43 1371\n",
      "Epoch: 043, Total Loss: 1.546, MDN: 1.541, Atom: 3.249, Bond: 1.724\n",
      "Error at 44 261\n",
      "Error at 44 273\n",
      "Error at 44 602\n",
      "Error at 44 762\n",
      "Epoch: 044, Total Loss: 1.543, MDN: 1.538, Atom: 3.247, Bond: 1.721\n",
      "Error at 45 227\n",
      "Error at 45 338\n",
      "Error at 45 619\n",
      "Error at 45 977\n",
      "Epoch: 045, Total Loss: 1.541, MDN: 1.536, Atom: 3.245, Bond: 1.718\n",
      "Error at 46 58\n",
      "Error at 46 217\n",
      "Error at 46 787\n",
      "Error at 46 1236\n",
      "Epoch: 046, Total Loss: 1.541, MDN: 1.536, Atom: 3.241, Bond: 1.713\n",
      "Error at 47 360\n",
      "Error at 47 432\n",
      "Error at 47 1165\n",
      "Error at 47 1348\n",
      "Epoch: 047, Total Loss: 1.540, MDN: 1.535, Atom: 3.240, Bond: 1.713\n",
      "Error at 48 202\n",
      "Error at 48 857\n",
      "Error at 48 874\n",
      "Error at 48 1294\n",
      "Epoch: 048, Total Loss: 1.539, MDN: 1.534, Atom: 3.239, Bond: 1.711\n",
      "Error at 49 290\n",
      "Error at 49 719\n",
      "Error at 49 1082\n",
      "Error at 49 1116\n",
      "Epoch: 049, Total Loss: 1.538, MDN: 1.533, Atom: 3.244, Bond: 1.716\n",
      "Error at 50 5\n",
      "Error at 50 166\n",
      "Error at 50 861\n",
      "Error at 50 1095\n",
      "Epoch: 050, Total Loss: 1.537, MDN: 1.532, Atom: 3.245, Bond: 1.719\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# from datetime import datetime\n",
    "# now = datetime.now()\n",
    "# print(now.strftime(\"Start date: %d/%m/%Y at %H:%M:%S\"))\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    #scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    total_loss, mdn_loss, atom_loss, bond_loss, count = 0, 0, 0, 0, 0\n",
    "    for data in loader_train:\n",
    "        try:\n",
    "            count+=1\n",
    "            #print(count)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #with torch.cuda.amp.autocast(enabled=True):\n",
    "            target, ligand = data\n",
    "            ligand, target = ligand.to(device), target.to(device)\n",
    "            atom_labels = torch.argmax(ligand.x, dim=1, keepdim=False)\n",
    "            bond_labels = torch.argmax(ligand.edge_attr, dim=1, keepdim=False)\n",
    "                \n",
    "            with torch.autocast(device_type='cuda'):\n",
    "                pi, sigma, mu, dist, atom_types, bond_types, batch = model(ligand, target)\n",
    "                # if count==68: \n",
    "                #     print(pi, sigma, mu, dist)\n",
    "                \n",
    "                mdn = mdn_loss_fn(pi, sigma, mu, dist)\n",
    "                mdn = mdn[torch.where(dist <= model.dist_threhold)[0]]\n",
    "                mdn = mdn.mean()\n",
    "                atom = F.cross_entropy(atom_types, atom_labels)\n",
    "                bond = F.cross_entropy(bond_types, bond_labels)\n",
    "                loss = mdn + (atom * aux_weight) + (bond * aux_weight)\n",
    "                #print('Total loss:', loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * (ligand.batch.max().item() + 1)\n",
    "            mdn_loss += mdn.item() * (ligand.batch.max().item() + 1)\n",
    "            atom_loss += atom.item() * (ligand.batch.max().item() + 1)\n",
    "            bond_loss += bond.item() * (ligand.batch.max().item() + 1)\n",
    "            \n",
    "            #print('Step, Total Loss: {:.3f}, MDN: {:.3f}'.format(total_loss, mdn_loss))\n",
    "            if np.isinf(mdn_loss) or np.isnan(mdn_loss): break\n",
    "        except:\n",
    "            print('Error at',epoch, count)\n",
    "            pass\n",
    "    return total_loss / len(loader_train.dataset), mdn_loss / len(loader_train.dataset), atom_loss / len(loader_train.dataset), bond_loss / len(loader_train.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    #loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    total_loss, mdn_loss, atom_loss, bond_loss = 0, 0, 0, 0\n",
    "    for data in loader:\n",
    "        try:\n",
    "            target ,ligand = data\n",
    "            ligand, target = ligand.to(device), target.to(device)\n",
    "            atom_labels = torch.argmax(ligand.x, dim=1, keepdim=False)\n",
    "            bond_labels = torch.argmax(ligand.edge_attr, dim=1, keepdim=False)\n",
    "            \n",
    "            pi, sigma, mu, dist, atom_types, bond_types, batch = model(ligand, target)\n",
    "                \n",
    "            mdn = mdn_loss_fn(pi, sigma, mu, dist)\n",
    "            mdn = mdn[torch.where(dist <= model.dist_threhold)[0]]\n",
    "            mdn = mdn.mean()\n",
    "            atom = F.cross_entropy(atom_types, atom_labels)\n",
    "            bond = F.cross_entropy(bond_types, bond_labels)\n",
    "            loss = mdn + (atom * aux_weight) + (bond * aux_weight)\n",
    "            \n",
    "            total_loss += loss.item() * (ligand.batch.max().item() + 1)\n",
    "            mdn_loss += mdn.item() * (ligand.batch.max().item() + 1)\n",
    "            atom_loss += atom.item() * (ligand.batch.max().item() + 1)\n",
    "            bond_loss += bond.item() * (ligand.batch.max().item() + 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return total_loss / len(loader.dataset), mdn_loss / len(loader.dataset), atom_loss / len(loader.dataset), bond_loss / len(loader.dataset)\n",
    "\n",
    "import pandas as pd\n",
    "prev_test_total_loss = 1000\n",
    "for epoch in range(1, epochs + 1):\n",
    "    total_loss, mdn_loss, atom_loss, bond_loss = train()\n",
    "    #print(total_loss)\n",
    "    if np.isinf(mdn_loss) or np.isnan(mdn_loss): \n",
    "        print('Inf ERROR')\n",
    "        break\n",
    "    test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss = test(loader_test)\n",
    "    losses.append([total_loss, mdn_loss, atom_loss, bond_loss, test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss])\n",
    "    \n",
    "    if test_mdn_loss <= prev_test_total_loss:\n",
    "        prev_test_total_loss = test_total_loss\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'rng_state': torch.get_rng_state(), 'total_loss': total_loss,  \n",
    "                    'mdn_loss': mdn_loss, 'atom_loss': atom_loss, 'bond_loss': bond_loss}, 'DeepDock_pdbbindv2019_13K_minTestLoss.chk')\n",
    "    l = pd.DataFrame(losses, columns= ['total_loss', 'mdn_loss', 'atom_loss', 'bond_loss', 'test_total_loss', 'test_mdn_loss', 'test_atom_loss', 'test_bond_loss'])\n",
    "    l.to_csv('DeepDock_pdbbindv2019_13K_loss.csv')\n",
    "      \n",
    "    print('Epoch: {:03d}, Total Loss: {:.3f}, MDN: {:.3f}, Atom: {:.3f}, Bond: {:.3f}'.format(epoch, total_loss, mdn_loss, atom_loss, bond_loss))\n",
    "    \n",
    "    if epoch % save_each == 0:\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'rng_state': torch.get_rng_state(), 'total_loss': total_loss,  \n",
    "                    'mdn_loss': mdn_loss, 'atom_loss': atom_loss, 'bond_loss': bond_loss}, 'DeepDock_pdbbindv2019_13K_epoch_%.3i.chk'%(epoch))\n",
    "        l = pd.DataFrame(losses, columns= ['total_loss', 'mdn_loss', 'atom_loss', 'bond_loss', 'test_total_loss', 'test_mdn_loss', 'test_atom_loss', 'test_bond_loss'])\n",
    "        l.to_csv('DeepDock_pdbbindv2019_13K_loss.csv')\n",
    "    \n",
    "torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'rng_state': torch.get_rng_state(), 'total_loss': total_loss,  \n",
    "            'mdn_loss': mdn_loss, 'atom_loss': atom_loss, 'bond_loss': bond_loss}, 'DeepDock_pdbbindv2019_13K_epoch_%.3i.chk'%(epoch))\n",
    "l = pd.DataFrame(losses, columns= ['total_loss', 'mdn_loss', 'atom_loss', 'bond_loss', 'test_total_loss', 'test_mdn_loss', 'test_atom_loss', 'test_bond_loss'])\n",
    "l.to_csv('DeepDock_pdbbindv2019_13K_loss.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('gnn_train')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed913640155bdbfc4c60680139b48fe20ea4f8c9af5dfbf51394c557aecd1dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
