{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell4/miniconda3/envs/gnn_train/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch_scatter import scatter_mean\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import normalized_cut, to_dense_batch, from_networkx\n",
    "from torch_geometric.nn import MetaLayer, SplineConv, max_pool, GlobalAttention\n",
    "from torch_geometric.transforms import FaceToEdge, Cartesian\n",
    "from torch_geometric.data import Batch, Data, Dataset\n",
    "from utils.distributions import *\n",
    "\n",
    "from utils import mol2graph\n",
    "from utils.data import read_ply\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "import py3Dmol\n",
    "#import pymesh\n",
    "from plyfile import PlyData\n",
    "\n",
    "DATA_PATH = '/home/dell4/king/202112_graphDrug/data_v2/PDBbind_v2020_other_PL/v2020-other-PL_minimized_copy/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# ID = '1a42'\n",
    "\n",
    "# # GET PROTEIN MESH\n",
    "# target_ply = DATA_PATH+'%s/%s_protein.ply'%(ID, ID)\n",
    "# target_mesh = Cartesian()(FaceToEdge()(read_ply(target_ply)))\n",
    "# # GET MOLECULE NETWORK\n",
    "# real_mol = Chem.MolFromMol2File(DATA_PATH+'%s/%s_ligand.mol2'%(ID, ID),sanitize=False, cleanupSubstructures=False)\n",
    "# mol_ntwk = from_networkx(mol2graph.mol_to_nx(real_mol))\n",
    "\n",
    "# mol_ntwk, target_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved data file. loading...\n",
      "Found 13785 complexes\n"
     ]
    }
   ],
   "source": [
    "# Prepare data files for training\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "\n",
    "def load_data(f_path):\n",
    "    with open(f_path, 'rb') as f:\n",
    "        mynewlist = pickle.load(f)\n",
    "        return mynewlist\n",
    "\n",
    "if os.path.exists('/home/dell4/king/202112_graphDrug/data_v2/v2020-other-PL_minimized.pkl'):\n",
    "    print('Found saved data file. loading...')\n",
    "    processed_data = load_data('/home/dell4/king/202112_graphDrug/data_v2/v2020-other-PL_minimized.pkl')\n",
    "    print('Found %s complexes'%(len(processed_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexes in training set: 11028\n",
      "Complexes in test set: 2757\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from model_v3 import LigandNet, TargetNet, AlphaDock, mdn_loss_fn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "# Split data and generate loaders\n",
    "from torch_geometric.loader import DataLoader\n",
    "split = int(len(processed_data)*0.8)\n",
    "train_data = processed_data[:split]\n",
    "test_data = processed_data[split:]\n",
    "print('Complexes in training set:', len(train_data))\n",
    "print('Complexes in test set:', len(test_data))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "ligand_model = LigandNet(28, residual_layers=10, dropout_rate=0.10)\n",
    "target_model = TargetNet(3, residual_layers=10, dropout_rate=0.10)\n",
    "model_1 = AlphaDock(ligand_model, target_model, hidden_dim=64, n_gaussians=10, dropout_rate=0.10, dist_threshold=7.).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.0001,\n",
    "                              betas=(0.9, 0.999), \n",
    "                              eps=1e-06, weight_decay=0.01)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "save_each=50\n",
    "aux_weight = 0.001\n",
    "losses = []\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1778"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(loader, model):\n",
    "    total_loss, mdn_loss, atom_loss, bond_loss, count = 0, 0, 0, 0, 0\n",
    "    for data in loader:  \n",
    "        count+=1\n",
    "        model.train()\n",
    "        target, ligand = data\n",
    "        ligand, target = ligand.to(device), target.to(device)\n",
    "\n",
    "        if torch.isnan(target.x).any() or torch.isnan(target.edge_attr).any() or torch.isnan(target.pos).any():\n",
    "            print('nan check failed for', count, '. Skipping step.')\n",
    "        elif torch.isnan(ligand.x).any() or torch.isnan(ligand.edge_attr).any() or torch.isnan(ligand.pos).any():\n",
    "            print('nan check failed for', count, '. Skipping step.')\n",
    "        else:            \n",
    "            atom_labels = torch.argmax(ligand.x, dim=1, keepdim=False)\n",
    "            bond_labels = torch.argmax(ligand.edge_attr, dim=1, keepdim=False)\n",
    "\n",
    "            pi, sigma, mu, dist, atom_types, bond_types, batch = model(ligand, target)\n",
    "            mdn = mdn_loss_fn(pi, sigma, mu, dist)\n",
    "            mdn = mdn[torch.where(dist <= model.dist_threhold)[0]]\n",
    "            mdn = mdn.mean()\n",
    "            atom = F.cross_entropy(atom_types, atom_labels)\n",
    "            bond = F.cross_entropy(bond_types, bond_labels)\n",
    "            loss = mdn + (atom * aux_weight) + (bond * aux_weight)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item() * (ligand.batch.max().item() + 1)\n",
    "            mdn_loss += mdn.item() * (ligand.batch.max().item() + 1)\n",
    "            atom_loss += atom.item() * (ligand.batch.max().item() + 1)\n",
    "            bond_loss += bond.item() * (ligand.batch.max().item() + 1)\n",
    "        # except:\n",
    "        #     print('ERROR at', count)\n",
    "        #     target, ligand = data\n",
    "        #     print('NAN CHECK', torch.isnan(target.x).any(), torch.isnan(target.edge_attr).any(), torch.isnan(target.pos).any())\n",
    "        #     #print(target.x, target.edge_attr, target.pos)\n",
    "        #     #print(ligand.x, ligand.edge_attr, ligand.pos)\n",
    "        #     break\n",
    "        \n",
    "    return total_loss / len(loader.dataset), mdn_loss / len(loader.dataset), atom_loss / len(loader.dataset), bond_loss / len(loader.dataset)\n",
    "\n",
    "def test(loader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss, mdn_loss, atom_loss, bond_loss, count = 0, 0, 0, 0, 0\n",
    "        for data in loader:\n",
    "            count+=1\n",
    "            target ,ligand = data\n",
    "            ligand, target = ligand.to(device), target.to(device)\n",
    "\n",
    "            if torch.isnan(target.x).any() or torch.isnan(target.edge_attr).any() or torch.isnan(target.pos).any():\n",
    "                print('nan check failed for', count, '. Skipping step.')\n",
    "            elif torch.isnan(ligand.x).any() or torch.isnan(ligand.edge_attr).any() or torch.isnan(ligand.pos).any():\n",
    "                print('nan check failed for', count, '. Skipping step.')\n",
    "            else:    \n",
    "                atom_labels = torch.argmax(ligand.x, dim=1, keepdim=False)\n",
    "                bond_labels = torch.argmax(ligand.edge_attr, dim=1, keepdim=False)\n",
    "                \n",
    "                pi, sigma, mu, dist, atom_types, bond_types, batch = model(ligand, target)\n",
    "                    \n",
    "                mdn = mdn_loss_fn(pi, sigma, mu, dist)\n",
    "                mdn = mdn[torch.where(dist <= model.dist_threhold)[0]]\n",
    "                mdn = mdn.mean()\n",
    "                atom = F.cross_entropy(atom_types, atom_labels)\n",
    "                bond = F.cross_entropy(bond_types, bond_labels)\n",
    "                loss = mdn + (atom * aux_weight) + (bond * aux_weight)\n",
    "                \n",
    "                total_loss += loss.item() * (ligand.batch.max().item() + 1)\n",
    "                mdn_loss += mdn.item() * (ligand.batch.max().item() + 1)\n",
    "                atom_loss += atom.item() * (ligand.batch.max().item() + 1)\n",
    "                bond_loss += bond.item() * (ligand.batch.max().item() + 1)\n",
    "\n",
    "        test_total_loss = total_loss / len(loader.dataset)                                                        \n",
    "        test_mdn_loss = mdn_loss / len(loader.dataset)\n",
    "        test_atom_loss = atom_loss / len(loader.dataset)\n",
    "        test_bond_loss = bond_loss / len(loader.dataset)\n",
    "    return test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss\n",
    "\n",
    "prev_test_total_loss = 1000\n",
    "import pandas as pd\n",
    "for epoch in range(1, epochs+1):\n",
    "    print('[EPOCH # {}/{}]'.format(epoch, epochs))\n",
    "    total_loss, mdn_loss, atom_loss, bond_loss = train(loader_train, model_1)\n",
    "    test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss = test(loader_test, model_1)\n",
    "    print('Epoch train: {:03d}, Total Loss: {:.3f}, MDN: {:.3f}, Atom: {:.3f}, Bond: {:.3f}'.format(epoch, total_loss, mdn_loss, atom_loss, bond_loss))\n",
    "    print('Epoch test: {:03d}, Total Loss: {:.3f}, MDN: {:.3f}, Atom: {:.3f}, Bond: {:.3f}'.format(epoch, test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss))\n",
    "    \n",
    "    losses.append([total_loss, mdn_loss, atom_loss, bond_loss, test_total_loss, test_mdn_loss, test_atom_loss, test_bond_loss])\n",
    "    if test_total_loss<=prev_test_total_loss:\n",
    "        torch.save({'epoch': epoch, 'model_state_dict': model_1.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'rng_state': torch.get_rng_state(), 'total_loss': total_loss,  \n",
    "                    'mdn_loss': mdn_loss, 'atom_loss': atom_loss, 'bond_loss': bond_loss}, 'checkpoints/model_alphadock_minloss.chk')\n",
    "\n",
    "l = pd.DataFrame(losses, columns= ['total_loss', 'mdn_loss', 'atom_loss', 'bond_loss', 'test_total_loss', 'test_mdn_loss', 'test_atom_loss', 'test_bond_loss'])\n",
    "l.to_csv('checkpoints/AlphaDock_pdbbindv2019_13K_loss.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('gnn_train')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed913640155bdbfc4c60680139b48fe20ea4f8c9af5dfbf51394c557aecd1dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
